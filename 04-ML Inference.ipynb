{"cells":[{"cell_type":"markdown","source":["# Fast ML Inference with Apache Spark"],"metadata":{}},{"cell_type":"markdown","source":["#### Apache Spark is great for training models across large datasets using a distributed compute cluster\n\nIn this webinar, we assume that you are familiar with the core Apache Spark Dataframe/Dataset and Machine Learning tools, and that you have encountered -- or want to avoid encountering! -- a common obstacle to deployment of Spark ML models.\n\n*Terminology:* In machine learning, the term \"inference\" refers to the process of using a model to make predictions on new data. That is, the model is *already* trained to a satisfactory level, and a business would like to deploy that model to predict (aka \"score\") new data records. An example might be a credit-card fraud model which estimates the likelihood of a transaction being fraudulent. Once the model is ready to go, it needs to be deployed (typically as a service) where it can be uses to test new incoming transactions.\n\n__What is the big challenge to deploying Spark ML models?__\n\nSpark is optimized to process large amounts of data using large amounts of compute hardware. When that large processing task is performing ML inference across a large set of data records (e.g., choosing the best marketing offer for each of 10 million mailing list recipients) and that inference can be done as a batch job, everything works great.\n\nHowever, in some use cases (e.g., fraud detection, intrusion detection, online ad bidding, etc.) there are different performance requirements: we may need to make a prediction very fast (just a few milliseconds) and for only a small number (maybe just one) data record.\n\nAnd, of course, many models may need to work both ways: large batch prediction as well as small, fast on-demand prediction.\n\n__Because Apache Spark was not designed to handle this small-data, low-latency case, its normal prediction APIs do not work at all in these situations.__\n\nHappily, there are numerous solutions to the problem, and we're here to discuss those so your project doesn't end up crashing and burning by using the wrong pattern."],"metadata":{}},{"cell_type":"markdown","source":["### Building a Very Simple Model to Demonstrate\n\nIn order to have a model to work with, we'll quickly train a very simple linear regression against the Diamonds (from R/ggplot) dataset.\n\nTo keep it incredibly simple, we'll look at just one predictor: the carat weight.\n\nHere's the code to train and eval the model:"],"metadata":{}},{"cell_type":"code","source":["input_file = \"/databricks-datasets/Rdatasets/data-001/csv/ggplot2/diamonds.csv\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\n\ndata = spark.read.option('header', True).csv(input_file) \\\n        .selectExpr('CAST(carat AS double) AS carat', 'CAST(price AS double) AS price')\n\ntrain, test = data.randomSplit([0.75, 0.25])\n\np = Pipeline(stages=[VectorAssembler(inputCols=['carat'], outputCol='caratVec'), \n                     LinearRegression(featuresCol='caratVec', labelCol='price')])\n\nmodel = p.fit(train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["And just as a smoke test, to make sure we're on the right track, we'll evaluate:"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n\nRegressionEvaluator(labelCol='price').evaluate(model.transform(test))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">3</span><span class=\"ansired\">]: </span>1545.0222133558912\n</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["Ok, we have a model, even if it's not great. Now let's generate some \"new data records\" which we would like to score using this model:"],"metadata":{}},{"cell_type":"code","source":["sample = spark.range(3).selectExpr(\"id + 1 as carat\")\nsample.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+\ncarat|\n+-----+\n    1|\n    2|\n    3|\n+-----+\n\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["And, as a baseline, we'll use the official, standard Spark ML Pipeline API to make our predictions:"],"metadata":{}},{"cell_type":"code","source":["model.transform(sample).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------+------------------+\ncarat|caratVec|        prediction|\n+-----+--------+------------------+\n    1|   [1.0]| 5504.515737030182|\n    2|   [2.0]|13275.098761820565|\n    3|   [3.0]|21045.681786610952|\n+-----+--------+------------------+\n\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["Notice that this prediction takes 200-500ms, far too long for the low-latency inference use cases we may need to target.\n\nTo make things worse, the demo environment I'm using today exhibits somewhat *better* performance on this task than a real (distributed) cluster. I.e., on a proper Spark cluster we would expect perf to get even worse.\n\n__Ok, what is the problem?__\n\nAs we've discussed, Spark is designed for large-scale distributed processing, so it spends a lot of time planning for then even when it's not necessary. In this case, we know the model is a trivial single multiply and single add to score a record. And even in Python we can do much better than Spark.\n\nHere are the parameters:"],"metadata":{}},{"cell_type":"code","source":["linearRegressionModel = model.stages[-1]\nc0 = linearRegressionModel.coefficients[0]\ni = linearRegressionModel.intercept\nprint(c0,i)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">7770.58302479 -2266.0672877602024\n</div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["And here are the predictions in Python:"],"metadata":{}},{"cell_type":"code","source":["[c0*carat + i for carat in [1,2,3]]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>[5504.5157370301822, 13275.098761820565, 21045.681786610952]\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["So Spark is adding 10x-100x overhead to this inference case."],"metadata":{}},{"cell_type":"markdown","source":["### What Can We Do?\n\nThe first and simplest option is to use the `Model.predict`.\n\nThis allows us to score a record on the driver, without using the Dataframe infrastructure and scheduler.\n\nThere are pros and cons to this approach, so let's try it and then review:"],"metadata":{}},{"cell_type":"code","source":["from pyspark.serializers import PickleSerializer\nfrom pyspark.ml.linalg import Vectors\n\ndef make_single_predicton(model, predictor):\n  data = bytearray(PickleSerializer().dumps(Vectors.dense([predictor])))\n  obj = sc._jvm.org.apache.spark.ml.python.MLSerDe.loads(data)\n  return model._java_obj.predict(obj)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["[make_single_predicton(linearRegressionModel, carat) for carat in [1,2,3]]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">9</span><span class=\"ansired\">]: </span>[5504.515737030182, 13275.098761820565, 21045.681786610952]\n</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["Pros:\n* It's fast -- close to the raw Python compute time, not the Spark-scheduled compute time\n* It maintains the original model's compute semantics exactly (since it uses the original model)\n* Doesn't require anything outside of Spark itself\n\nCons: \n* API is only public in the most recent version(s) of Spark (2.4 or so)\n* API in 2.4 is only in Scala, so we need to go \"under the hood\" a little to use it in Python\n* Most critically, it doesn't support `Pipeline` or any feature pre-processing, so it's up to us to perform any prep on the data record and deliver a `Vector` to the model\n* Spark is an awfully large and complex (and expensive) piece of software to use to perform a multiply and an add"],"metadata":{}},{"cell_type":"markdown","source":["### What Else Can We Try, Sticking Close to Spark?\n\nMicrosoft has released (as part of their Azure ML stack and MMLSpark) an adapter for Spark Structured Streaming that allows you to expose a streaming job as a REST service.\n\nCombining that adapter with Spark's experimental (2.3+) Continuous / Low-Latency Streaming feature allows us to get a REST service for scoring records quickly.\n\n*Note: this demo requires installing Microsoft's open-source MMLSpark as a package - see https://github.com/Azure/mmlspark *"],"metadata":{}},{"cell_type":"code","source":["%sh \n\nrm -rf /tmp/ck\nmkdir /tmp/ck"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["import mmlspark\nfrom pyspark.sql.functions import udf, col, length\nfrom pyspark.sql.types import *\n\ndf = spark.readStream.continuousServer().address(\"localhost\", 8888, \"my_api\").load() \\\n     .parseRequest(StructType().add(\"carat\", DoubleType()))\n\nreplies = model.transform(df).makeReply(\"prediction\")\n\nserver = replies\\\n    .writeStream.continuousServer().trigger(continuous=\"1 second\") \\\n    .replyTo(\"my_api\") \\\n    .queryName(\"my_query\") \\\n    .option(\"checkpointLocation\", \"file:///tmp/ck\") \\\n    .start()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ImportError</span>                               Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3829983292049375&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span><span class=\"ansigreen\">import</span> mmlspark<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansigreen\">from</span> pyspark<span class=\"ansiyellow\">.</span>sql<span class=\"ansiyellow\">.</span>functions <span class=\"ansigreen\">import</span> udf<span class=\"ansiyellow\">,</span> col<span class=\"ansiyellow\">,</span> length<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> <span class=\"ansigreen\">from</span> pyspark<span class=\"ansiyellow\">.</span>sql<span class=\"ansiyellow\">.</span>types <span class=\"ansigreen\">import</span> <span class=\"ansiyellow\">*</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> df <span class=\"ansiyellow\">=</span> spark<span class=\"ansiyellow\">.</span>readStream<span class=\"ansiyellow\">.</span>continuousServer<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>address<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;localhost&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">8888</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;my_api&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>load<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span>      <span class=\"ansiyellow\">.</span>parseRequest<span class=\"ansiyellow\">(</span>StructType<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>add<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;carat&quot;</span><span class=\"ansiyellow\">,</span> DoubleType<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ImportError</span>: No module named &apos;mmlspark&apos;</div>"]}}],"execution_count":23},{"cell_type":"code","source":["import requests\n\nfor carat in [1,2,3]:\n  data = u'{\"carat\":' + str(carat) + '}'\n  r = requests.post(data=data, url=\"http://localhost:8888/my_api\")\n  print(\"Response {}\".format(r.text))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ConnectionError</span>                           Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3829983292049376&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      3</span> <span class=\"ansigreen\">for</span> carat <span class=\"ansigreen\">in</span> <span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">,</span><span class=\"ansicyan\">2</span><span class=\"ansiyellow\">,</span><span class=\"ansicyan\">3</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span>   data <span class=\"ansiyellow\">=</span> <span class=\"ansiblue\">u&apos;{&quot;carat&quot;:&apos;</span> <span class=\"ansiyellow\">+</span> str<span class=\"ansiyellow\">(</span>carat<span class=\"ansiyellow\">)</span> <span class=\"ansiyellow\">+</span> <span class=\"ansiblue\">&apos;}&apos;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 5</span><span class=\"ansiyellow\">   </span>r <span class=\"ansiyellow\">=</span> requests<span class=\"ansiyellow\">.</span>post<span class=\"ansiyellow\">(</span>data<span class=\"ansiyellow\">=</span>data<span class=\"ansiyellow\">,</span> url<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">&quot;http://localhost:8888/my_api&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      6</span>   print<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Response {}&quot;</span><span class=\"ansiyellow\">.</span>format<span class=\"ansiyellow\">(</span>r<span class=\"ansiyellow\">.</span>text<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/requests/api.py</span> in <span class=\"ansicyan\">post</span><span class=\"ansiblue\">(url, data, json, **kwargs)</span>\n<span class=\"ansigreen\">    108</span>     &quot;&quot;&quot;\n<span class=\"ansigreen\">    109</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 110</span><span class=\"ansiyellow\">     </span><span class=\"ansigreen\">return</span> request<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;post&apos;</span><span class=\"ansiyellow\">,</span> url<span class=\"ansiyellow\">,</span> data<span class=\"ansiyellow\">=</span>data<span class=\"ansiyellow\">,</span> json<span class=\"ansiyellow\">=</span>json<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kwargs<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    111</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    112</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/requests/api.py</span> in <span class=\"ansicyan\">request</span><span class=\"ansiblue\">(method, url, **kwargs)</span>\n<span class=\"ansigreen\">     54</span>     <span class=\"ansired\"># cases, and look like a memory leak in others.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     55</span>     <span class=\"ansigreen\">with</span> sessions<span class=\"ansiyellow\">.</span>Session<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">as</span> session<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 56</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> session<span class=\"ansiyellow\">.</span>request<span class=\"ansiyellow\">(</span>method<span class=\"ansiyellow\">=</span>method<span class=\"ansiyellow\">,</span> url<span class=\"ansiyellow\">=</span>url<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kwargs<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     57</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     58</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/requests/sessions.py</span> in <span class=\"ansicyan\">request</span><span class=\"ansiblue\">(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)</span>\n<span class=\"ansigreen\">    473</span>         }\n<span class=\"ansigreen\">    474</span>         send_kwargs<span class=\"ansiyellow\">.</span>update<span class=\"ansiyellow\">(</span>settings<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 475</span><span class=\"ansiyellow\">         </span>resp <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>send<span class=\"ansiyellow\">(</span>prep<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>send_kwargs<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    476</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    477</span>         <span class=\"ansigreen\">return</span> resp<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/requests/sessions.py</span> in <span class=\"ansicyan\">send</span><span class=\"ansiblue\">(self, request, **kwargs)</span>\n<span class=\"ansigreen\">    594</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    595</span>         <span class=\"ansired\"># Send the request</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 596</span><span class=\"ansiyellow\">         </span>r <span class=\"ansiyellow\">=</span> adapter<span class=\"ansiyellow\">.</span>send<span class=\"ansiyellow\">(</span>request<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kwargs<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    597</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    598</span>         <span class=\"ansired\"># Total elapsed time of the request (approximately)</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/requests/adapters.py</span> in <span class=\"ansicyan\">send</span><span class=\"ansiblue\">(self, request, stream, timeout, verify, cert, proxies)</span>\n<span class=\"ansigreen\">    485</span>                 <span class=\"ansigreen\">raise</span> ProxyError<span class=\"ansiyellow\">(</span>e<span class=\"ansiyellow\">,</span> request<span class=\"ansiyellow\">=</span>request<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    486</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 487</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> ConnectionError<span class=\"ansiyellow\">(</span>e<span class=\"ansiyellow\">,</span> request<span class=\"ansiyellow\">=</span>request<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    488</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    489</span>         <span class=\"ansigreen\">except</span> ClosedPoolError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ConnectionError</span>: HTTPConnectionPool(host=&apos;localhost&apos;, port=8888): Max retries exceeded with url: /my_api (Caused by NewConnectionError(&apos;&lt;requests.packages.urllib3.connection.HTTPConnection object at 0x7f750bff2048&gt;: Failed to establish a new connection: [Errno 111] Connection refused&apos;,))</div>"]}}],"execution_count":24},{"cell_type":"code","source":["server.stop()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3829983292049377&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>server<span class=\"ansiyellow\">.</span>stop<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;server&apos; is not defined</div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["This approach is just as fast as `model.predict` once it's warmed up... and it's much better because it allows us to reuse the feature engineering `Pipeline` and maintain its semantics. Let's look at the pros and cons here:\n\n__Pros__\n* Maintains full `Pipeline` API and semantics\n* Uses native Spark APIs (ML Pipelines, Dataframe, Structured Streaming)\n* Offers a fast REST service\n\n__Cons__\n* Involves deploying a large software platform to perform small, limited operations\n* Requires an unsual archectural adaptation\n* Relies on experimental continuous streaming mode\n* Substantial complexity - my motto: never use streaming [for anything] if you don't have to, and if you do, then treat it as a first-class citizen"],"metadata":{}},{"cell_type":"markdown","source":["### How Can We Improve This Further?\n\nArguably, the model -- with its simple rules and minimal compute needs -- should be able to be extracted from Spark (or any training environment) and deployed elsewhere.\n\nThere are several ways to do this, and we'll start with the one that is stays closest to Spark.\n\nMLeap replicated the Spark ML components in a way that allows them to run locally (not distributed) against a data structure called a LeapFrame, which behaves much like a small, local DataFrame. MLeap models can be deployed in a small MLeap runtime that you can use as a black-box service, or (since it's open source) you can integrate into any JVM-based service app.\n\n*Note: this demo requires installing both the MLeap Scala libraries and the MLeap Python front-end; see http://mleap-docs.combust.ml/getting-started/spark.html and http://mleap-docs.combust.ml/getting-started/py-spark.html *"],"metadata":{}},{"cell_type":"code","source":["import mleap.pyspark\nfrom mleap.pyspark.spark_support import SimpleSparkSerializer"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ImportError</span>                               Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3829983292049380&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span><span class=\"ansigreen\">import</span> mleap<span class=\"ansiyellow\">.</span>pyspark<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansigreen\">from</span> mleap<span class=\"ansiyellow\">.</span>pyspark<span class=\"ansiyellow\">.</span>spark_support <span class=\"ansigreen\">import</span> SimpleSparkSerializer<span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ImportError</span>: No module named &apos;mleap&apos;</div>"]}}],"execution_count":28},{"cell_type":"code","source":["%sh rm /tmp/pyspark.example.zip"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">rm: cannot remove &apos;/tmp/pyspark.example.zip&apos;: No such file or directory\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["model.serializeToBundle(\"jar:file:/tmp/pyspark.example.zip\", model.transform(sample))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3829983292049382&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>model<span class=\"ansiyellow\">.</span>serializeToBundle<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;jar:file:/tmp/pyspark.example.zip&quot;</span><span class=\"ansiyellow\">,</span> model<span class=\"ansiyellow\">.</span>transform<span class=\"ansiyellow\">(</span>sample<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;PipelineModel&apos; object has no attribute &apos;serializeToBundle&apos;</div>"]}}],"execution_count":30},{"cell_type":"code","source":["%sh ls -la /tmp"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">total 6008\ndrwxrwxrwt 1 root   root      4096 Apr 30 19:09 .\ndrwxr-xr-x 1 root   root      4096 Apr 30 13:18 ..\n-rw-r--r-- 1 root   root        22 Apr 30 13:18 chauffeur-daemon-params\n-rw-r--r-- 1 root   root         5 Apr 30 13:18 chauffeur-daemon.pid\n-rw-r--r-- 1 ubuntu ubuntu     156 Apr 30 13:18 chauffeur-env.sh\ndrwxr-xr-x 2 root   root      4096 Apr 30 19:09 ck\n-rw-r--r-- 1 ubuntu ubuntu     133 Apr 30 13:18 custom-spark.conf\n-rw-r--r-- 1 root   root   3192559 Jan 18 19:41 diamonds.csv\n-rw-r--r-- 1 root   root        19 Apr 30 13:18 driver-daemon-params\n-rw-r--r-- 1 root   root         5 Apr 30 13:18 driver-daemon.pid\n-rw-r--r-- 1 root   root      2454 Apr 30 13:18 driver-env.sh\ndrwxr-xr-x 2 root   root      4096 Apr 30 13:20 hsperfdata_root\ndrwxrwxrwt 2 root   root      4096 Apr 30 13:18 .ICE-unix\nsrw------- 1 root   root         0 Apr 30 13:19 .java_pid2002\n-rw-r--r-- 1 root   root     23504 Apr 30 18:54 model\ndrwxr-xr-x 3 root   root      4096 Apr 30 13:19 Rserv\ndrwx------ 2 root   root      4096 Apr 30 13:19 Rtmpd8QZ9I\n-rw------- 1 root   root         0 Apr 30 13:18 tmp.6tDfiKjioa\ndrwxrwxrwt 2 root   root      4096 Apr 30 13:18 .X11-unix\n-rw-r--r-- 1 root   root   2871006 Apr 22 03:13 zips.json\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["Here we can see the exported artifact, called an __MLeap Bundle__ ready to use in the MLeap runtime, or a JVM app of your own creation.\n\nPros:\n* Maintains Spark semantics\n* Separates model from Spark platform\n  * Allows fast scoring in lots of other places without requiring Spark\n* Has a multiyear track record\n* Supported by MLflow platform\n* F/OSS\n* Also supports \"bundling\" and exporting models training in Scikit-Learn and TensorFlow\n\nCons:\n* Only runs with the MLeap runtime\n* Not an industry standard format\n* Won't interoperate with other tools outside of the { Spark, TensorFlow, Scikit-Learn, MLeap } ecosystem\n* Is not a huge OSS project; could be some risk in the future\n\nIf you want to see an example that doesn't just show the Spark export, but also the the deployment (in MLeap Serving), take a look at my tutorial (https://www.youtube.com/watch?v=KOehXxEgXFM). The first part explains the issues we've discussed today and builds a model; the last 5-6 minutes shows deployment and scoring."],"metadata":{}},{"cell_type":"markdown","source":["### What About Industry-Standard Model Formats for Deployment?\n\nThere are three formats worth considering:\n* PMML\n* PFA\n* ONNX"],"metadata":{}},{"cell_type":"markdown","source":["### PMML\n\n<img src=\"https://materials.s3.amazonaws.com/i/PMML_Logo.png\">\n\nThis is the grand-daddy standard format, dating to around 1996. It is widely supported by proprietary (non-OSS) machine learning tools, and has some spotty support in OSS.\n\n__Example__\n\nHere is an example of a logistic regression classifier trained using R on the Iris dataset:\n\n(http://dmg.org/pmml/pmml_examples/rattle_pmml_examples/IrisMultinomReg.xml)\n\n<img src=\"https://materials.s3.amazonaws.com/i/UFJlBqq.png\" width=1000>\n\n__The good:__\n* XML based\n* Widely used, well known\n* Interoperable\n\n__The bad:__\n* Spark does not support exporting Pipelines as PMML\n  * The tools which allow Spark Pipeline -> PMML export are almost entirely part of the Openscoring/JPMML ecosystem, which is very fine work but published under the AGPL (extremely non-permissive) license, and commercial licenses are supported by a very small company.\n* There is no permissive, open-source, widely used high-performance serving library for PMML models ... again you'll run into JPMML almost everywhere ...\n  * The permissive licensed version is very old; the modern version is AGPL\n\n*PMML might be right for you, but that requires considerations beyond the purely technical*"],"metadata":{}},{"cell_type":"markdown","source":["### PFA\n\n<img src=\"https://materials.s3.amazonaws.com/i/PFA_Logo-200x200.png\">\n\nPFA (created around 2016) is intended to be a Modern Replacement for PMML, and offers a variety of advantages over PMML.\n\n##### \"As data analyses mature, they must be hardened — they must have fewer dependencies, a more maintainable structure, and they must be robust against errors.\" - DMG\n\n<img src=\"https://materials.s3.amazonaws.com/i/KuQPUbx.png\" width=800>"],"metadata":{}},{"cell_type":"markdown","source":["__Example__\n\nHere are some data records:\n\n<img src=\"https://materials.s3.amazonaws.com/i/vsvToXy.png\" width=600>\n\nAnd a PFA document which returns the square-root of the sum of the squares of a record's x, y, and z values:\n\n<img src=\"https://materials.s3.amazonaws.com/i/tIlag9o.png\" width=600>"],"metadata":{}},{"cell_type":"markdown","source":["__PFA Pros:__\n* Well-known semantic and security guarantees\n* Open-source, permissively licensed implementations for JVM and Python\n* Supports extremely large variety of operations\n* Provides interchangeable compact/binary and human-readable representations\n\n__Cons:__\n* Very little industry support so far\n* IBM Open Source launched a project (Aardpfark) to support Spark ML Pipeline export to PFA\n  * But it only has a single v 0.1 release thus far, June 2018, and it's missing some critical pieces to make it useful\n\n*PFA might be the future, but it definitely isn't the present*"],"metadata":{}},{"cell_type":"markdown","source":["### ONNX (Open Neural Network eXchange)\n\nOriginally created by Facebook and Microsoft as an industry collaboration for import/export of neural networks, it has grown to include support for \"traditional\" ML models, interop with many software libraries, and has both software (CPU + GPU accelerated) and hardware (Intel, Qualcomm, etc.) runtimes.\n\nhttps://onnx.ai/\n\n* Created by Facebook and Microsoft; AWS now on board\n* DAG-based model\n* Built-in operators, data types\n* Extensible -- e.g., ONNX-ML\n* Goal is to allow tools to share a single model format\n\n<img src=\"https://materials.s3.amazonaws.com/i/9byVguG.png\" width=500>\n\nPros:\n* Most major deep learning tools have ONNX support\n* MIT license makes it both OSS and business friendly\n* Seems to achieve its first-order goal of allowing tools interop for neural nets\n* As of 2019, is the closest thing we have to an open, versatile, next-gen format *with wide support*\n* Protobuf format is compact and typesafe\n* Biggest weakness was \"classical\" ML and feature engineering support -- this is now being shored up\n* Microsoft open-sourced (Dec 2018) a high-perf runtime (GPU, CPU, language bindings, etc.) https://azure.microsoft.com/en-us/blog/onnx-runtime-is-now-open-source/\n  * Being used as part of Windows ML / Azure ML\n  * https://github.com/Microsoft/onnxruntime\n* In Q1-Q2 of 2019, Microsoft added a Spark ML Pipeline exporter to the `onnxmltools` project\n  * https://github.com/onnx/onnxmltools\n  \n*Of the \"standard/open\" formats, ONNX clearly has the most momentum in the past year or two.*\n\nLet's take a look at exporting SparkML to ONNX!"],"metadata":{}},{"cell_type":"code","source":["dbutils.library.installPyPI(\"onnxmltools\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">18</span><span class=\"ansired\">]: </span>True\n</div>"]}}],"execution_count":39},{"cell_type":"code","source":["from onnxmltools import convert_sparkml\nfrom onnxmltools.convert.sparkml import buildInitialTypesSimple, buildInputDictSimple"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":40},{"cell_type":"code","source":["model_onnx = convert_sparkml(model, 'Diamonds', buildInitialTypesSimple(test.select(\"carat\")))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The maximum opset needed by this model is only 4.\nThe maximum opset needed by this model is only 1.\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":["print(model_onnx)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ir_version: 5\nproducer_name: &quot;OnnxMLTools&quot;\nproducer_version: &quot;1.4.1&quot;\ndomain: &quot;onnxconverter-common&quot;\nmodel_version: 0\ndoc_string: &quot;&quot;\ngraph {\n  node {\n    input: &quot;carat&quot;\n    output: &quot;caratVec&quot;\n    name: &quot;Concat&quot;\n    op_type: &quot;Concat&quot;\n    attribute {\n      name: &quot;axis&quot;\n      i: 1\n      type: INT\n    }\n    domain: &quot;&quot;\n  }\n  node {\n    input: &quot;caratVec&quot;\n    output: &quot;prediction&quot;\n    name: &quot;LinearRegressor&quot;\n    op_type: &quot;LinearRegressor&quot;\n    attribute {\n      name: &quot;coefficients&quot;\n      floats: 7770.5830078125\n      type: FLOATS\n    }\n    attribute {\n      name: &quot;intercepts&quot;\n      floats: -2266.0673828125\n      type: FLOATS\n    }\n    domain: &quot;ai.onnx.ml&quot;\n  }\n  name: &quot;Diamonds&quot;\n  input {\n    name: &quot;carat&quot;\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 1\n          }\n        }\n      }\n    }\n  }\n  output {\n    name: &quot;prediction&quot;\n    type {\n      tensor_type {\n        elem_type: 1\n        shape {\n          dim {\n            dim_value: 1\n          }\n          dim {\n            dim_value: 1\n          }\n        }\n      }\n    }\n  }\n}\nopset_import {\n  domain: &quot;&quot;\n  version: 4\n}\nopset_import {\n  domain: &quot;ai.onnx.ml&quot;\n  version: 1\n}\n\n</div>"]}}],"execution_count":42},{"cell_type":"code","source":["with open(\"/tmp/diamonds.onnx\", \"wb\") as f:\n    f.write(model_onnx.SerializeToString())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"code","source":["%sh cp /tmp/diamonds.onnx /dbfs/FileStore/diamonds.onnx"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":44},{"cell_type":"code","source":["%sh ls -la /dbfs/FileStore/*.onnx"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">ls: cannot access &apos;/dbfs/FileStore/*.onnx&apos;: No such file or directory\n</div>"]}}],"execution_count":45},{"cell_type":"markdown","source":["Ok so we have a ONNX model from out Spark Pipeline. To show that it actually works, and complete an end-to-end demo, in the next module we'll look at a simple Python app that uses Microsoft's high-perf `onnxruntime` to score some requests in a web service."],"metadata":{}},{"cell_type":"markdown","source":["You don't need to download your ONNX model, but if you want to, you can <a href=\"/files/diamonds.onnx\">click here</a> to download (e.g., if you'd like to build a scoring/inference server on your own machine.)"],"metadata":{}}],"metadata":{"name":"04-ML Inference","notebookId":3829983292049352},"nbformat":4,"nbformat_minor":0}
