{"cells":[{"cell_type":"markdown","source":["##Vectorized PandasUDF + Keras for Inference\n\nOne of the exciting things we can do with Arrow/Vectorized PandasUDF is efficiently integrate Spark with numeric or even GPU code that was *not* designed with Spark in mind.\n\nFor example, we might have a model that we've build with Keras+TensorFlow -- without Spark in the picture at all -- and then efficiently use that model to perform inference on big datasets with Spark.\n\nIn this module, we'll do just that: we'll train a simple neural network using Keras, save it to disk, and then use it from Spark via PandasUDF."],"metadata":{"id":"CgNj2jhSGmgJ","colab_type":"text"}},{"cell_type":"markdown","source":["We'll start by using Pandas to read our Diamonds dataset, and to save time (and featurization) we'll just use the 6 continuous variables in our model to predict price."],"metadata":{"id":"Gt8g3wjfGmgK","colab_type":"text"}},{"cell_type":"code","source":["%%sh \n\nwget https://materials.s3.amazonaws.com/res/data/diamonds.csv -O /tmp/diamonds.csv"],"metadata":{"id":"mj7h8FArHSkl","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">--2019-04-30 18:51:03--  https://materials.s3.amazonaws.com/res/data/diamonds.csv\nResolving materials.s3.amazonaws.com (materials.s3.amazonaws.com)... 52.218.225.115\nConnecting to materials.s3.amazonaws.com (materials.s3.amazonaws.com)|52.218.225.115|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3192559 (3.0M) [application/octet-stream]\nSaving to: ‘/tmp/diamonds.csv’\n\n     0K .......... .......... .......... .......... ..........  1% 23.2M 0s\n    50K .......... .......... .......... .......... ..........  3% 27.5M 0s\n   100K .......... .......... .......... .......... ..........  4% 36.9M 0s\n   150K .......... .......... .......... .......... ..........  6% 21.3M 0s\n   200K .......... .......... .......... .......... ..........  8% 44.7M 0s\n   250K .......... .......... .......... .......... ..........  9% 35.3M 0s\n   300K .......... .......... .......... .......... .......... 11% 26.8M 0s\n   350K .......... .......... .......... .......... .......... 12% 46.6M 0s\n   400K .......... .......... .......... .......... .......... 14% 46.6M 0s\n   450K .......... .......... .......... .......... .......... 16% 41.2M 0s\n   500K .......... .......... .......... .......... .......... 17% 40.0M 0s\n   550K .......... .......... .......... .......... .......... 19% 37.1M 0s\n   600K .......... .......... .......... .......... .......... 20% 46.0M 0s\n   650K .......... .......... .......... .......... .......... 22% 49.6M 0s\n   700K .......... .......... .......... .......... .......... 24% 48.5M 0s\n   750K .......... .......... .......... .......... .......... 25% 63.9M 0s\n   800K .......... .......... .......... .......... .......... 27% 58.2M 0s\n   850K .......... .......... .......... .......... .......... 28% 82.6M 0s\n   900K .......... .......... .......... .......... .......... 30% 67.8M 0s\n   950K .......... .......... .......... .......... .......... 32% 71.6M 0s\n  1000K .......... .......... .......... .......... .......... 33% 65.3M 0s\n  1050K .......... .......... .......... .......... .......... 35% 68.1M 0s\n  1100K .......... .......... .......... .......... .......... 36% 63.5M 0s\n  1150K .......... .......... .......... .......... .......... 38%  108M 0s\n  1200K .......... .......... .......... .......... .......... 40% 53.3M 0s\n  1250K .......... .......... .......... .......... .......... 41%  116M 0s\n  1300K .......... .......... .......... .......... .......... 43% 40.4M 0s\n  1350K .......... .......... .......... .......... .......... 44%  105M 0s\n  1400K .......... .......... .......... .......... .......... 46% 61.0M 0s\n  1450K .......... .......... .......... .......... .......... 48%  107M 0s\n  1500K .......... .......... .......... .......... .......... 49% 55.6M 0s\n  1550K .......... .......... .......... .......... .......... 51%  132M 0s\n  1600K .......... .......... .......... .......... .......... 52% 76.7M 0s\n  1650K .......... .......... .......... .......... .......... 54%  114M 0s\n  1700K .......... .......... .......... .......... .......... 56%  105M 0s\n  1750K .......... .......... .......... .......... .......... 57% 89.3M 0s\n  1800K .......... .......... .......... .......... .......... 59% 98.0M 0s\n  1850K .......... .......... .......... .......... .......... 60% 76.8M 0s\n  1900K .......... .......... .......... .......... .......... 62% 87.3M 0s\n  1950K .......... .......... .......... .......... .......... 64% 86.4M 0s\n  2000K .......... .......... .......... .......... .......... 65% 81.5M 0s\n  2050K .......... .......... .......... .......... .......... 67% 87.3M 0s\n  2100K .......... .......... .......... .......... .......... 68%  108M 0s\n  2150K .......... .......... .......... .......... .......... 70% 80.7M 0s\n  2200K .......... .......... .......... .......... .......... 72% 70.2M 0s\n  2250K .......... .......... .......... .......... .......... 73%  141M 0s\n  2300K .......... .......... .......... .......... .......... 75%  127M 0s\n  2350K .......... .......... .......... .......... .......... 76% 87.9M 0s\n  2400K .......... .......... .......... .......... .......... 78% 76.3M 0s\n  2450K .......... .......... .......... .......... .......... 80% 78.5M 0s\n  2500K .......... .......... .......... .......... .......... 81%  171M 0s\n  2550K .......... .......... .......... .......... .......... 83% 84.0M 0s\n  2600K .......... .......... .......... .......... .......... 84% 98.4M 0s\n  2650K .......... .......... .......... .......... .......... 86% 89.0M 0s\n  2700K .......... .......... .......... .......... .......... 88%  103M 0s\n  2750K .......... .......... .......... .......... .......... 89%  107M 0s\n  2800K .......... .......... .......... .......... .......... 91% 89.4M 0s\n  2850K .......... .......... .......... .......... .......... 93%  155M 0s\n  2900K .......... .......... .......... .......... .......... 94%  132M 0s\n  2950K .......... .......... .......... .......... .......... 96%  120M 0s\n  3000K .......... .......... .......... .......... .......... 97%  111M 0s\n  3050K .......... .......... .......... .......... .......... 99% 91.3M 0s\n  3100K .......... .......                                    100%  110M=0.05s\n\n2019-04-30 18:51:03 (63.6 MB/s) - ‘/tmp/diamonds.csv’ saved [3192559/3192559]\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["import pandas as pd\nimport IPython.display as disp\n\ninput_file = \"/tmp/diamonds.csv\"\n\ndf = pd.read_csv(input_file, header = 0)\ndf.drop(df.columns[0], axis=1, inplace=True)\ndf.drop(df.columns[1:4], axis=1, inplace=True)\ndisp.display(df)"],"metadata":{"id":"_ZYIRL-VGmgL","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">       carat  depth  table  price     x     y     z\n0       0.23   61.5   55.0    326  3.95  3.98  2.43\n1       0.21   59.8   61.0    326  3.89  3.84  2.31\n2       0.23   56.9   65.0    327  4.05  4.07  2.31\n3       0.29   62.4   58.0    334  4.20  4.23  2.63\n4       0.31   63.3   58.0    335  4.34  4.35  2.75\n5       0.24   62.8   57.0    336  3.94  3.96  2.48\n6       0.24   62.3   57.0    336  3.95  3.98  2.47\n7       0.26   61.9   55.0    337  4.07  4.11  2.53\n8       0.22   65.1   61.0    337  3.87  3.78  2.49\n9       0.23   59.4   61.0    338  4.00  4.05  2.39\n10      0.30   64.0   55.0    339  4.25  4.28  2.73\n11      0.23   62.8   56.0    340  3.93  3.90  2.46\n12      0.22   60.4   61.0    342  3.88  3.84  2.33\n13      0.31   62.2   54.0    344  4.35  4.37  2.71\n14      0.20   60.2   62.0    345  3.79  3.75  2.27\n15      0.32   60.9   58.0    345  4.38  4.42  2.68\n16      0.30   62.0   54.0    348  4.31  4.34  2.68\n17      0.30   63.4   54.0    351  4.23  4.29  2.70\n18      0.30   63.8   56.0    351  4.23  4.26  2.71\n19      0.30   62.7   59.0    351  4.21  4.27  2.66\n20      0.30   63.3   56.0    351  4.26  4.30  2.71\n21      0.23   63.8   55.0    352  3.85  3.92  2.48\n22      0.23   61.0   57.0    353  3.94  3.96  2.41\n23      0.31   59.4   62.0    353  4.39  4.43  2.62\n24      0.31   58.1   62.0    353  4.44  4.47  2.59\n25      0.23   60.4   58.0    354  3.97  4.01  2.41\n26      0.24   62.5   57.0    355  3.97  3.94  2.47\n27      0.30   62.2   57.0    357  4.28  4.30  2.67\n28      0.23   60.5   61.0    357  3.96  3.97  2.40\n29      0.23   60.9   57.0    357  3.96  3.99  2.42\n...      ...    ...    ...    ...   ...   ...   ...\n53910   0.70   60.5   58.0   2753  5.74  5.77  3.48\n53911   0.57   59.8   60.0   2753  5.43  5.38  3.23\n53912   0.61   61.8   59.0   2753  5.48  5.40  3.36\n53913   0.80   64.2   58.0   2753  5.84  5.81  3.74\n53914   0.84   63.7   59.0   2753  5.94  5.90  3.77\n53915   0.77   62.1   56.0   2753  5.84  5.86  3.63\n53916   0.74   63.1   59.0   2753  5.71  5.74  3.61\n53917   0.90   63.2   60.0   2753  6.12  6.09  3.86\n53918   0.76   59.3   62.0   2753  5.93  5.85  3.49\n53919   0.76   62.2   55.0   2753  5.89  5.87  3.66\n53920   0.70   62.4   60.0   2755  5.57  5.61  3.49\n53921   0.70   62.8   60.0   2755  5.59  5.65  3.53\n53922   0.70   63.1   59.0   2755  5.67  5.58  3.55\n53923   0.73   61.3   56.0   2756  5.80  5.84  3.57\n53924   0.73   61.6   55.0   2756  5.82  5.84  3.59\n53925   0.79   61.6   56.0   2756  5.95  5.97  3.67\n53926   0.71   61.9   56.0   2756  5.71  5.73  3.54\n53927   0.79   58.1   59.0   2756  6.06  6.13  3.54\n53928   0.79   61.4   58.0   2756  6.03  5.96  3.68\n53929   0.71   61.4   56.0   2756  5.76  5.73  3.53\n53930   0.71   60.5   55.0   2756  5.79  5.74  3.49\n53931   0.71   59.8   62.0   2756  5.74  5.73  3.43\n53932   0.70   60.5   59.0   2757  5.71  5.76  3.47\n53933   0.70   61.2   59.0   2757  5.69  5.72  3.49\n53934   0.72   62.7   59.0   2757  5.69  5.73  3.58\n53935   0.72   60.8   57.0   2757  5.75  5.76  3.50\n53936   0.72   63.1   55.0   2757  5.69  5.75  3.61\n53937   0.70   62.8   60.0   2757  5.66  5.68  3.56\n53938   0.86   61.0   58.0   2757  6.15  6.12  3.74\n53939   0.75   62.2   55.0   2757  5.83  5.87  3.64\n\n[53940 rows x 7 columns]\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["We'll do a train/test split, and look at a few rows as a sanity check:"],"metadata":{"id":"zKIZe-KiGmgO","colab_type":"text"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n\nX = df.drop(df.columns[3], axis=1)\ny = df.iloc[:,3:4]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nprint(X[:5])\n\nprint(y[:5])"],"metadata":{"id":"BO_ku5A-GmgO","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">   carat  depth  table     x     y     z\n0   0.23   61.5   55.0  3.95  3.98  2.43\n1   0.21   59.8   61.0  3.89  3.84  2.31\n2   0.23   56.9   65.0  4.05  4.07  2.31\n3   0.29   62.4   58.0  4.20  4.23  2.63\n4   0.31   63.3   58.0  4.34  4.35  2.75\n   price\n0    326\n1    326\n2    327\n3    334\n4    335\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["Now we'll build a simple feed-forward perceptron network in Keras, and train it for a minute or so, then check our performance"],"metadata":{"id":"5lwgC6qtGmgQ","colab_type":"text"}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["dbutils.library.installPyPI(\"findspark\") "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">41</span><span class=\"ansired\">]: </span>True\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["import tensorflow as tf\nimport numpy as np\n\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Dense(16, input_dim=6, kernel_initializer='normal', activation='relu')) \nmodel.add(tf.keras.layers.Dense(1, kernel_initializer='normal', activation='linear'))\n\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\nmodel.fit(X_train, y_train, epochs=64, batch_size=128, validation_split=0.1, verbose=2)\n\nscores = model.evaluate(X_test, y_test)\nprint(\"\\nroot %s: %f\" % (model.metrics_names[1], np.sqrt(scores[1])))"],"metadata":{"id":"kIiRK2N8GmgR","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">WARNING:tensorflow:From /local_disk0/pythonVirtualEnvDirs/virtualEnv-eca6c570-7f18-49d4-a2b3-a33b3c579ca4/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /local_disk0/pythonVirtualEnvDirs/virtualEnv-eca6c570-7f18-49d4-a2b3-a33b3c579ca4/lib/python3.5/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 38836 samples, validate on 4316 samples\nWARNING:tensorflow:From /local_disk0/pythonVirtualEnvDirs/virtualEnv-eca6c570-7f18-49d4-a2b3-a33b3c579ca4/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/64\n - 1s - loss: 30947533.3662 - mean_squared_error: 30947528.0000 - val_loss: 28328675.5700 - val_mean_squared_error: 28328676.0000\nEpoch 2/64\n - 0s - loss: 28189147.9464 - mean_squared_error: 28189148.0000 - val_loss: 24583030.8267 - val_mean_squared_error: 24583032.0000\nEpoch 3/64\n - 0s - loss: 23808754.3360 - mean_squared_error: 23808754.0000 - val_loss: 20234934.5922 - val_mean_squared_error: 20234930.0000\nEpoch 4/64\n - 1s - loss: 19645973.5975 - mean_squared_error: 19645970.0000 - val_loss: 16879783.8378 - val_mean_squared_error: 16879784.0000\nEpoch 5/64\n - 0s - loss: 16871948.0801 - mean_squared_error: 16871950.0000 - val_loss: 15111471.4995 - val_mean_squared_error: 15111471.0000\nEpoch 6/64\n - 0s - loss: 15598971.1398 - mean_squared_error: 15598972.0000 - val_loss: 14530729.5885 - val_mean_squared_error: 14530730.0000\nEpoch 7/64\n - 0s - loss: 15195743.7679 - mean_squared_error: 15195746.0000 - val_loss: 14404787.3494 - val_mean_squared_error: 14404787.0000\nEpoch 8/64\n - 0s - loss: 15081493.2275 - mean_squared_error: 15081488.0000 - val_loss: 14362067.7183 - val_mean_squared_error: 14362068.0000\nEpoch 9/64\n - 0s - loss: 15020463.8206 - mean_squared_error: 15020459.0000 - val_loss: 14315722.8304 - val_mean_squared_error: 14315722.0000\nEpoch 10/64\n - 0s - loss: 14961055.0147 - mean_squared_error: 14961056.0000 - val_loss: 14257631.8888 - val_mean_squared_error: 14257630.0000\nEpoch 11/64\n - 0s - loss: 14895548.7200 - mean_squared_error: 14895543.0000 - val_loss: 14193376.0936 - val_mean_squared_error: 14193376.0000\nEpoch 12/64\n - 0s - loss: 14824181.3958 - mean_squared_error: 14824182.0000 - val_loss: 14118125.0454 - val_mean_squared_error: 14118126.0000\nEpoch 13/64\n - 0s - loss: 14745834.3618 - mean_squared_error: 14745836.0000 - val_loss: 14046609.8888 - val_mean_squared_error: 14046610.0000\nEpoch 14/64\n - 0s - loss: 14657627.3575 - mean_squared_error: 14657627.0000 - val_loss: 13948552.9045 - val_mean_squared_error: 13948555.0000\nEpoch 15/64\n - 0s - loss: 14535988.4295 - mean_squared_error: 14535988.0000 - val_loss: 13816274.2424 - val_mean_squared_error: 13816276.0000\nEpoch 16/64\n - 0s - loss: 14394183.7933 - mean_squared_error: 14394180.0000 - val_loss: 13678057.5607 - val_mean_squared_error: 13678057.0000\nEpoch 17/64\n - 0s - loss: 14241520.3859 - mean_squared_error: 14241520.0000 - val_loss: 13517724.4773 - val_mean_squared_error: 13517724.0000\nEpoch 18/64\n - 0s - loss: 14077978.9392 - mean_squared_error: 14077981.0000 - val_loss: 13358610.0982 - val_mean_squared_error: 13358612.0000\nEpoch 19/64\n - 0s - loss: 13901552.9719 - mean_squared_error: 13901553.0000 - val_loss: 13184160.8508 - val_mean_squared_error: 13184163.0000\nEpoch 20/64\n - 0s - loss: 13710612.8602 - mean_squared_error: 13710609.0000 - val_loss: 12990781.4476 - val_mean_squared_error: 12990781.0000\nEpoch 21/64\n - 0s - loss: 13505630.0396 - mean_squared_error: 13505630.0000 - val_loss: 12788098.9629 - val_mean_squared_error: 12788100.0000\nEpoch 22/64\n - 0s - loss: 13283484.5233 - mean_squared_error: 13283485.0000 - val_loss: 12578370.6395 - val_mean_squared_error: 12578373.0000\nEpoch 23/64\n - 1s - loss: 13047012.5020 - mean_squared_error: 13047013.0000 - val_loss: 12330810.8234 - val_mean_squared_error: 12330811.0000\nEpoch 24/64\n - 1s - loss: 12793075.2238 - mean_squared_error: 12793071.0000 - val_loss: 12079007.9407 - val_mean_squared_error: 12079009.0000\nEpoch 25/64\n - 0s - loss: 12520940.2375 - mean_squared_error: 12520942.0000 - val_loss: 11806491.2688 - val_mean_squared_error: 11806492.0000\nEpoch 26/64\n - 0s - loss: 12229161.9355 - mean_squared_error: 12229167.0000 - val_loss: 11511614.8360 - val_mean_squared_error: 11511616.0000\nEpoch 27/64\n - 0s - loss: 11917616.9270 - mean_squared_error: 11917615.0000 - val_loss: 11203861.5014 - val_mean_squared_error: 11203862.0000\nEpoch 28/64\n - 0s - loss: 11586582.1592 - mean_squared_error: 11586581.0000 - val_loss: 10878754.7961 - val_mean_squared_error: 10878756.0000\nEpoch 29/64\n - 0s - loss: 11237480.6447 - mean_squared_error: 11237482.0000 - val_loss: 10528915.8647 - val_mean_squared_error: 10528914.0000\nEpoch 30/64\n - 0s - loss: 10871408.3143 - mean_squared_error: 10871405.0000 - val_loss: 10165795.6515 - val_mean_squared_error: 10165796.0000\nEpoch 31/64\n - 0s - loss: 10489576.5897 - mean_squared_error: 10489575.0000 - val_loss: 9794320.2660 - val_mean_squared_error: 9794321.0000\nEpoch 32/64\n - 0s - loss: 10093408.3501 - mean_squared_error: 10093409.0000 - val_loss: 9410042.1395 - val_mean_squared_error: 9410042.0000\nEpoch 33/64\n - 0s - loss: 9686958.4590 - mean_squared_error: 9686959.0000 - val_loss: 9019803.8239 - val_mean_squared_error: 9019805.0000\nEpoch 34/64\n - 0s - loss: 9276040.5723 - mean_squared_error: 9276040.0000 - val_loss: 8621162.9907 - val_mean_squared_error: 8621162.0000\nEpoch 35/64\n - 0s - loss: 8861342.6260 - mean_squared_error: 8861339.0000 - val_loss: 8218123.6960 - val_mean_squared_error: 8218123.0000\nEpoch 36/64\n - 0s - loss: 8445742.8764 - mean_squared_error: 8445742.0000 - val_loss: 7823084.4838 - val_mean_squared_error: 7823085.0000\nEpoch 37/64\n - 0s - loss: 8034519.6619 - mean_squared_error: 8034518.5000 - val_loss: 7426503.2683 - val_mean_squared_error: 7426503.0000\nEpoch 38/64\n - 0s - loss: 7628712.0640 - mean_squared_error: 7628713.5000 - val_loss: 7044043.6070 - val_mean_squared_error: 7044043.5000\nEpoch 39/64\n - 0s - loss: 7231723.4934 - mean_squared_error: 7231721.0000 - val_loss: 6669026.7711 - val_mean_squared_error: 6669027.0000\nEpoch 40/64\n - 0s - loss: 6846018.7056 - mean_squared_error: 6846020.5000 - val_loss: 6302299.8128 - val_mean_squared_error: 6302299.5000\nEpoch 41/64\n - 0s - loss: 6473815.4219 - mean_squared_error: 6473815.0000 - val_loss: 5952022.4073 - val_mean_squared_error: 5952023.5000\nEpoch 42/64\n - 0s - loss: 6118500.8805 - mean_squared_error: 6118502.5000 - val_loss: 5622202.6691 - val_mean_squared_error: 5622202.5000\nEpoch 43/64\n - 0s - loss: 5780411.7071 - mean_squared_error: 5780413.5000 - val_loss: 5312114.1381 - val_mean_squared_error: 5312114.5000\nEpoch 44/64\n - 0s - loss: 5461191.6818 - mean_squared_error: 5461191.0000 - val_loss: 5021305.0199 - val_mean_squared_error: 5021306.0000\nEpoch 45/64\n - 0s - loss: 5163575.8144 - mean_squared_error: 5163576.0000 - val_loss: 4746964.4852 - val_mean_squared_error: 4746964.5000\nEpoch 46/64\n - 0s - loss: 4889010.2417 - mean_squared_error: 4889010.0000 - val_loss: 4491732.4819 - val_mean_squared_error: 4491733.0000\nEpoch 47/64\n - 0s - loss: 4637195.1039 - mean_squared_error: 4637196.0000 - val_loss: 4266931.8976 - val_mean_squared_error: 4266932.0000\nEpoch 48/64\n - 0s - loss: 4408739.5207 - mean_squared_error: 4408741.0000 - val_loss: 4061109.4650 - val_mean_squared_error: 4061109.5000\nEpoch 49/64\n - 0s - loss: 4203288.9172 - mean_squared_error: 4203289.5000 - val_loss: 3880535.8480 - val_mean_squared_error: 3880535.7500\nEpoch 50/64\n - 0s - loss: 4018868.4498 - mean_squared_error: 4018867.5000 - val_loss: 3716897.2910 - val_mean_squared_error: 3716897.2500\nEpoch 51/64\n - 1s - loss: 3854376.1144 - mean_squared_error: 3854376.5000 - val_loss: 3570991.0014 - val_mean_squared_error: 3570991.0000\nEpoch 52/64\n - 1s - loss: 3706209.1693 - mean_squared_error: 3706209.2500 - val_loss: 3437181.1145 - val_mean_squared_error: 3437181.0000\nEpoch 53/64\n - 0s - loss: 3571475.6879 - mean_squared_error: 3571476.5000 - val_loss: 3316782.7834 - val_mean_squared_error: 3316783.0000\nEpoch 54/64\n - 0s - loss: 3449177.5031 - mean_squared_error: 3449177.2500 - val_loss: 3205887.5100 - val_mean_squared_error: 3205887.0000\nEpoch 55/64\n - 1s - loss: 3338259.6112 - mean_squared_error: 3338261.0000 - val_loss: 3108994.7987 - val_mean_squared_error: 3108994.5000\nEpoch 56/64\n - 1s - loss: 3239874.7234 - mean_squared_error: 3239874.5000 - val_loss: 3023162.7641 - val_mean_squared_error: 3023162.7500\nEpoch 57/64\n - 0s - loss: 3152335.1219 - mean_squared_error: 3152335.7500 - val_loss: 2941362.0489 - val_mean_squared_error: 2941362.5000\nEpoch 58/64\n - 0s - loss: 3072793.8667 - mean_squared_error: 3072794.5000 - val_loss: 2875967.1196 - val_mean_squared_error: 2875966.7500\nEpoch 59/64\n - 0s - loss: 2997313.6905 - mean_squared_error: 2997313.2500 - val_loss: 2804296.5762 - val_mean_squared_error: 2804296.5000\nEpoch 60/64\n - 0s - loss: 2926668.9899 - mean_squared_error: 2926669.2500 - val_loss: 2737614.6638 - val_mean_squared_error: 2737615.0000\nEpoch 61/64\n - 0s - loss: 2863404.9464 - mean_squared_error: 2863404.7500 - val_loss: 2677118.0153 - val_mean_squared_error: 2677118.0000\nEpoch 62/64\n - 0s - loss: 2805922.4281 - mean_squared_error: 2805923.5000 - val_loss: 2625572.6426 - val_mean_squared_error: 2625572.5000\nEpoch 63/64\n - 0s - loss: 2754551.0700 - mean_squared_error: 2754550.5000 - val_loss: 2583169.9951 - val_mean_squared_error: 2583169.7500\nEpoch 64/64\n - 1s - loss: 2709860.8029 - mean_squared_error: 2709861.0000 - val_loss: 2540631.2931 - val_mean_squared_error: 2540631.2500\n\r   32/10788 [..............................] - ETA: 0s - loss: 4056505.0000 - mean_squared_error: 4056505.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2528/10788 [======&gt;.......................] - ETA: 0s - loss: 2412151.2967 - mean_squared_error: 2412151.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4960/10788 [============&gt;.................] - ETA: 0s - loss: 2473988.4843 - mean_squared_error: 2473988.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7456/10788 [===================&gt;..........] - ETA: 0s - loss: 2474723.5856 - mean_squared_error: 2474723.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9952/10788 [==========================&gt;...] - ETA: 0s - loss: 2570188.0006 - mean_squared_error: 2570187.2500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10788/10788 [==============================] - 0s 20us/sample - loss: 2566066.6402 - mean_squared_error: 2566066.7500\n\nroot mean_squared_error: 1601.894775\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["model.save(\"/tmp/model\")"],"metadata":{"id":"FPwRxAheGmgT","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n!wget -q https://www-us.apache.org/dist/spark/spark-2.4.2/spark-2.4.2-bin-hadoop2.7.tgz\n!tar xf spark-2.4.2-bin-hadoop2.7.tgz\n!pip install -q findspark"],"metadata":{"id":"VTH-uBeTIpTx","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["import os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\nos.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.2-bin-hadoop2.7\""],"metadata":{"id":"fllgekk9IzWg","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["import findspark\n#findspark.init()\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"metadata":{"id":"P48b2U3JI-W-","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["Ok, now let's get Spark DataFrame with our test data. In real life, we'd read this directly from S3, HDFS, Kafka, or wherever.\n\nBut since this test set is already on the driver (and not very big), we can make a distributed Spark DF from the Pandas DF."],"metadata":{"id":"rzlBsRYMGmgY","colab_type":"text"}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n\ntestDF = spark.createDataFrame(pd.DataFrame(X_test, columns=[\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]))\n\ntestDF.show()"],"metadata":{"id":"hYctmgyyGmgZ","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----+-----+----+----+----+\ncarat|depth|table|   x|   y|   z|\n+-----+-----+-----+----+----+----+\n 0.55| 61.6| 55.0|5.33|5.28|3.27|\n 0.71| 61.7| 60.0| 5.7|5.74|3.53|\n  0.7| 61.5| 57.0|5.68|5.71| 3.5|\n 0.33| 59.1| 60.0|4.48|4.52|2.66|\n  0.4| 60.4| 57.0|4.76|4.81|2.89|\n 0.71| 62.0| 59.0|5.69|5.65|3.52|\n  0.5| 61.8| 56.0|5.15|5.11|3.17|\n 1.25| 60.6| 60.0|6.92|6.95| 4.2|\n 0.46| 61.7| 60.0|4.94|4.98|3.06|\n  0.3| 63.4| 57.0|4.31|4.27|2.72|\n 0.57| 61.9| 55.0|5.34|5.36|3.31|\n 0.43| 61.8| 55.0|4.85|4.89|3.01|\n 1.29| 60.8| 55.0|7.03|7.12| 4.3|\n 0.78| 62.3| 56.0|5.91|5.88|3.67|\n 1.01| 59.8| 59.0|6.55| 6.5| 3.9|\n 0.52| 60.9| 58.0|5.22|5.16|3.16|\n  0.7| 61.9| 58.0|5.74|5.69|3.54|\n 1.02| 57.5| 62.0|6.62| 6.6| 3.8|\n 0.55| 62.7| 59.0|5.22|5.25|3.28|\n 1.74| 61.6| 59.0| 7.7|7.62|4.72|\n+-----+-----+-----+----+----+----+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["When our data shows up, we'll have to reshape it a little bit, and then we can do a regular keras `model.predict()` on it. A  raw prediction looks like this:"],"metadata":{"id":"lc_sASa_Gmgh","colab_type":"text"}},{"cell_type":"code","source":["model.predict(X_test[:5])"],"metadata":{"id":"PG0ZSuqGGmgi","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">60</span><span class=\"ansired\">]: </span>\narray([[ 2125.22412109],\n       [ 3067.08618164],\n       [ 3267.25585938],\n       [  732.95611572],\n       [ 1155.28955078]], dtype=float32)\n</div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["That's almost perfect ... but Spark is going to expect a Pandas Series of outputs from the PandasUDF (one for each input)"],"metadata":{"id":"l7UYHbsAGmgk","colab_type":"text"}},{"cell_type":"code","source":["pd.Series(model.predict(X_test[:5]).flatten())"],"metadata":{"id":"10Heo_MaGmgk","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">61</span><span class=\"ansired\">]: </span>\n0    2125.224121\n1    3067.086182\n2    3267.255859\n3     732.956116\n4    1155.289551\ndtype: float32\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["Let's try it:\n\n*Note: in real life, don't load the model on each call ... make sure the model is available ahead of time on the executors and just loaded once (e.g. by distributing a module/pyfile)*"],"metadata":{"id":"3svuX85xGmgn","colab_type":"text"}},{"cell_type":"code","source":["! pip install pyarrow"],"metadata":{"id":"DNFHdaDnN8RB","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["from pyspark.sql.functions import *\nfrom pyspark.sql.functions import PandasUDFType\n\nimport numpy as np\n\n@pandas_udf(\"double\", PandasUDFType.SCALAR)\ndef keras_predict(*v):\n  # reshape to records x len(v) columns\n  reshaped = np.asarray(v).reshape(len(v), -1).transpose()\n  keras_model = tf.keras.models.load_model('/tmp/model')\n  return pd.Series(keras_model.predict(reshaped).flatten())    "],"metadata":{"id":"NgNOYgF9Gmgn","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["And now we can `keras_predict` on the columns in the Spark DataFrame:"],"metadata":{"id":"62YWYALzGmgt","colab_type":"text"}},{"cell_type":"code","source":["testDF.select(keras_predict(*testDF.columns)).show()"],"metadata":{"id":"4wGIE0JCGmgu","colab_type":"code","colab":{}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------------------------------+\nkeras_predict(carat, depth, table, x, y, z)|\n+-------------------------------------------+\n                           2125.22412109375|\n                          3067.086181640625|\n                             3267.255859375|\n                          732.9561157226562|\n                           1155.28955078125|\n                          3000.066650390625|\n                           1653.34912109375|\n                            7366.7314453125|\n                           1272.41357421875|\n                         436.80877685546875|\n                          2251.216552734375|\n                           1293.30419921875|\n                            8262.3720703125|\n                          3983.386474609375|\n                                 6007.90625|\n                          1710.121337890625|\n                          3209.865966796875|\n                           6143.64404296875|\n                         1691.0284423828125|\n                           10172.3486328125|\n+-------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["And now ... we've got Spark and all of our Python goodness playing nice!"],"metadata":{"id":"3SHE6YZXGmgw","colab_type":"text"}}],"metadata":{"name":"02_GoogleColab_VectorizedInference","notebookId":3829983292049327,"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"02-ML-VectorizedInference.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
