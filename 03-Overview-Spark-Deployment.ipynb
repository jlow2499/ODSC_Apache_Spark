{"cells":[{"cell_type":"markdown","source":["## Model Deployment for SparkML"],"metadata":{}},{"cell_type":"markdown","source":["#### I'm a Data Scientist, Why Do I Care About Deployment Architectures?\n\n... Because they can (especially if misunderstood) impact the tools you can use.\n\nMisunderstanding SparkML deployment has led some companies who loved Spark to force data scientists to use\n* more difficult, less enjoyable or performant open-source tools\n* proprietary tools\n* occasionally inappropriate tools\n\nSpark may (or may not) be right for you, but we don't want our hand forced by misunderstandings."],"metadata":{}},{"cell_type":"markdown","source":["#### Batch Inference, Medium-Latency, Low-Latency\n\n* Distributed Job-Scheduling Time Overhead\n  * Negligible for batch or high-latency jobs\n  * But: we want (need?) to avoid this in low-latency cases\n  \n* Data Processing Platform Space Overhead\n  * In some cases we may want or need to avoid the overhead of the ML platform itelf (e.g., Spark, H2O, or whatever)\n  \n* Batch: ~1-2 seconds or higher\n* Medium-Latency: 100ms up to 1-2 seconds\n* Low-Latency: Less than 100ms; in some cases measured in nanoseconds\n\nThe batch case is obvious/easy with SparkML, and we've seen how to leverage GPU and/or Python tooling as part of that"],"metadata":{}},{"cell_type":"markdown","source":["####Medium-Latency\n\nYou may be able to:\n\n* Run Spark in Local Mode (scale-out service)\n* Create `LocalRelation` driver-based DataFrame\n* Use \"regular\" `model.predict` or `pipeline_model.transform` APIs\n\nIf this works for you, it is very easy. But it still may not be a great idea architecturally (we'll come back to this)"],"metadata":{}},{"cell_type":"markdown","source":["d #### What About Fast Prediction on Just a Few Vectors?\n\nFor low-latency inference on one or a small set of vectors, *today* you will want to look at complementary tools. (This may change later, but that's true of anything :) )"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":6}],"metadata":{"name":"03-Overview-Spark-Deployment","notebookId":3829983292049400},"nbformat":4,"nbformat_minor":0}
